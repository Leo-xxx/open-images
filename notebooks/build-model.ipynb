{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the classifier\n",
    "\n",
    "This notebook builds a CNN model based on our custom open sandwiches dataset. It is meant to be self-contained, runnable end-to-end, and to save the CNN to disk at a specific location at the end of the notebook - more on that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../data/ 2>/dev/null\n",
    "!mkdir ../data/images_cropped/ 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by localizing the dataset that we are working with. If you are running this notebook locally and have already localized the data (e.g. you've used `openimager` to download them again yourself) you can skip this line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4.Package.install(\n",
    "    'quilt/open_images', \n",
    "    registry='s3://alpha-quilt-storage', \n",
    "    dest='../data/images_cropped/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# remove the hot dog class if present to make this a binary classification problem\n",
    "# this is an artifact from an earlier version of this demo which was three-class instead of two-class\n",
    "!rm -rf ../data/images_cropped/quilt/open_images/Hot_dog 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network definition and training code follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rescale=1/255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1/255\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../data/images_cropped/quilt/open_images/',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    '../data/images_cropped/quilt/open_images/',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(128, 128, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss=binary_crossentropy,\n",
    "              optimizer=RMSprop(lr=0.0005),  # half of the default lr\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "sample_size = len(list(pathlib.Path('../data/images_cropped/').rglob('./*')))\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=sample_size // batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=round(sample_size * 0.2) // batch_size,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally once we've fitted the model it's time to save it to disk. We will save the model artifact to a very particular location on disk: `/opt/ml/model/clf.h5`.\n",
    "\n",
    "This is done so that this notebook is compatible with AWS SageMaker. I personally ran this notebook training session using a Quilt AWS account and the [alekseylearn](https://github.com/ResidentMario/alekseylearn) library (an alpha-level side project) using the following CLI command:\n",
    "\n",
    "```bash\n",
    "alekseylearn fit build.ipynb --config.output_path=\"s3://alpha-quilt-storage/aleksey/sagemaker/alekseylearn\" --config.role_name=\"aleksey_sagemaker_role\"\n",
    "```\n",
    "\n",
    "However it is much easier and less yak-shavy to just run this notebook locally and save the model someplace on your local disk instead. To do that change the savefile locations in the following code line to something more convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if running locally change this to a convenient local path, e.g. './clf.h5'\n",
    "model.save(\"/opt/ml/model/clf.h5\")\n",
    "\n",
    "import json\n",
    "with open(\"/opt/ml/model/history.json\", \"w\") as f:\n",
    "    # this also\n",
    "    json.dump(hist.history, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
