{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t4-image-metadata-push\n",
    "\n",
    "This notebook handles formatting metadata annotations for the images and uploading those images and annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the core image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alex/miniconda3/envs/quilt-open-images-dev/lib/python3.6/site-packages/numpy/lib/arraysetops.py:522: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.read_csv(\"data/metadata/train-annotations-bbox.csv\", index_col=0)\n",
    "b = pd.read_csv(\"data/metadata/train-annotations-human-imagelabels-boxable.csv\", index_col=0)\n",
    "c = pd.read_csv(\"data/metadata/train-images-ids.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imglist = a['ImageID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1743042"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.set_index(\"ImageID\")\n",
    "b = b.set_index(\"ImageID\")\n",
    "c = c.set_index(\"ImageID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineAnnotationsByID(ImageID):\n",
    "    bboxes   = pd.DataFrame(a.loc[ImageID])\n",
    "    labels   = pd.DataFrame(b.loc[ImageID])\n",
    "    img_meta = c.loc[ImageID]\n",
    "    \n",
    "    out = dict(img_meta)\n",
    "    out['bboxes'] = list(bboxes.apply(lambda srs: dict(srs), axis='columns'))\n",
    "    out['labels'] = list(labels.apply(lambda srs: dict(srs), axis='columns'))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too many images, takes too long, for now.\n",
    "\n",
    "# from tqdm import tqdm_notebook\n",
    "\n",
    "# meta_entries = []\n",
    "# for ImageID in tqdm_notebook(imglist):\n",
    "#     meta_entries.append(defineAnnotationsByID(ImageID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code could generate the full metadata annotations for the images as a JSON blob (though I need to also throw the image label IDs into the mix). It would take about 3 hours to generate the full dataset metadata entry in JSON.\n",
    "\n",
    "The images can be localized by passing through the Flickr API, but the Flickr API rate limits to 3600 requests per hour (documented [here](https://www.flickr.com/services/developer/api/)). Respecting this rate limit, it would take almost 500 hours, or approximately 20 days of continuous work, in order to download the images from Flickr. Not practical.\n",
    "\n",
    "The images could be downloaded more quickly as a direct ZIP, but I don't have enough storage space on my local drive to do it, as the zipped file is over a terabyte in size.\n",
    "\n",
    "The best way to populate the images would be to use an Amazon EC2 instance as an intermediary, per [this comment](https://datascience.stackexchange.com/questions/5589/downloading-a-large-dataset-on-the-web-directly-into-aws-s3).\n",
    "\n",
    "I can push the raw CSV files right away, and build some summaries around those; and do the `README.md`.\n",
    "\n",
    "For the images, we can now move to defining a working set we are comfortable pushing through the T4. I'm thinking `{sandwich, hot dog, hamburger}`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
